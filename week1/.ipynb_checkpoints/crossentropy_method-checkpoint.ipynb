{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Crossentropy method\n",
    "\n",
    "This notebook will teach you to solve reinforcement learning problems with crossentropy method. We'll follow-up by scaling everything up and using neural network policy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys, os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+\n",
      "|\u001b[35mR\u001b[0m: | : :G|\n",
      "| : | : : |\n",
      "| : : : : |\n",
      "| |\u001b[43m \u001b[0m: | : |\n",
      "|\u001b[34;1mY\u001b[0m| : |B: |\n",
      "+---------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import gym\n",
    "import numpy as np\n",
    "\n",
    "env = gym.make(\"Taxi-v3\")\n",
    "env.reset()\n",
    "env.render()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n_states=500, n_actions=6\n"
     ]
    }
   ],
   "source": [
    "n_states = env.observation_space.n\n",
    "n_actions = env.action_space.n\n",
    "\n",
    "print(\"n_states=%i, n_actions=%i\" % (n_states, n_actions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create stochastic policy\n",
    "\n",
    "This time our policy should be a probability distribution.\n",
    "\n",
    "```policy[s,a] = P(take action a | in state s)```\n",
    "\n",
    "Since we still use integer state and action representations, you can use a 2-dimensional array to represent the policy.\n",
    "\n",
    "Please initialize the policy __uniformly__, that is, probabililities of all actions should be equal."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(500, 6)\n"
     ]
    }
   ],
   "source": [
    "def initialize_policy(n_states, n_actions):\n",
    "    \n",
    "    policy= np.ones((n_states,n_actions))/n_actions\n",
    "    print(policy.shape)\n",
    "    return policy\n",
    "\n",
    "policy = initialize_policy(n_states, n_actions)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert type(policy) in (np.ndarray, np.matrix)\n",
    "assert np.allclose(policy, 1./n_actions)\n",
    "assert np.allclose(np.sum(policy, axis=1), 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "s = env.reset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.16666667, 0.16666667, 0.16666667, 0.16666667, 0.16666667,\n",
       "       0.16666667])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "policy[s]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Play the game\n",
    "\n",
    "Just like before, but we also record all states and actions we took."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_session(env, policy, t_max=10**4):\n",
    "    \"\"\"\n",
    "    Play game until end or for t_max ticks.\n",
    "    :param policy: an array of shape [n_states,n_actions] with action probabilities\n",
    "    :returns: list of states, list of actions and sum of rewards\n",
    "    \"\"\"\n",
    "    states, actions = [], []\n",
    "    total_reward = 0.\n",
    "\n",
    "    s = env.reset()\n",
    "\n",
    "    for t in range(t_max):\n",
    "        a = np.random.choice(list(range(n_actions)),p=policy[s])\n",
    "\n",
    "        new_s, r, done, info = env.step(a)\n",
    "\n",
    "        # Record information we just got from the environment.\n",
    "        states.append(s)\n",
    "        actions.append(a)\n",
    "        total_reward += r\n",
    "\n",
    "        s = new_s\n",
    "        if done:\n",
    "            break\n",
    "\n",
    "    return states, actions, total_reward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Vadimcg\\AppData\\Local\\Temp\\ipykernel_6012\\914564096.py:4: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  assert type(r) in [float, np.float]\n"
     ]
    }
   ],
   "source": [
    "s, a, r = generate_session(env, policy)\n",
    "assert type(s) == type(a) == list\n",
    "assert len(s) == len(a)\n",
    "assert type(r) in [float, np.float]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x14eefb4ccd0>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# let's see the initial reward distribution\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "\n",
    "sample_rewards = [generate_session(env, policy, t_max=1000)[-1] for _ in range(200)]\n",
    "\n",
    "plt.hist(sample_rewards, bins=20)\n",
    "plt.vlines([np.percentile(sample_rewards, 50)], [0], [100], label=\"50'th percentile\", color='green')\n",
    "plt.vlines([np.percentile(sample_rewards, 90)], [0], [100], label=\"90'th percentile\", color='red')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Array :  [1, 2, 3, 4, 5, 6]\n",
      "50 percentile :  2.25\n"
     ]
    }
   ],
   "source": [
    "\n",
    "arr = [1,2,3,4,5,6]\n",
    "print(\"Array : \",arr)\n",
    "\n",
    "x = np.percentile(arr, 25)\n",
    "print(\"50 percentile : \",x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Crossentropy method steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def select_elites(states_batch, actions_batch, rewards_batch, percentile):\n",
    "    \n",
    "    \n",
    "    \"\"\"\n",
    "    Select states and actions from games that have rewards >= percentile\n",
    "    :param states_batch: list of lists of states, states_batch[session_i][t]\n",
    "    :param actions_batch: list of lists of actions, actions_batch[session_i][t]\n",
    "    :param rewards_batch: list of rewards, rewards_batch[session_i]\n",
    "\n",
    "    :returns: elite_states,elite_actions, both 1D lists of states and respective actions from elite sessions\n",
    "\n",
    "    Please return elite states and actions in their original order \n",
    "    [i.e. sorted by session number and timestep within session]\n",
    "\n",
    "    If you are confused, see examples below. Please don't assume that states are integers\n",
    "    (they will become different later).\n",
    "    \"\"\"\n",
    "    \n",
    "    states=np.array(states_batch)\n",
    "    actions=np.array(actions_batch)\n",
    "    rewards=np.array(rewards_batch)\n",
    "    print( np.percentile(rewards,percentile))\n",
    "\n",
    "    reward_threshold =  np.percentile(rewards,percentile)\n",
    "    elite_states=[]\n",
    "    elite_actions=[]\n",
    "\n",
    "    for index in range(len(rewards)):\n",
    "        if rewards[index] >= np.percentile(rewards,percentile):\n",
    "            elite_states+=states[index]\n",
    "            elite_actions+=actions[index]\n",
    "            \n",
    "\n",
    "    return elite_states, elite_actions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.0\n",
      "3.6\n",
      "4.8\n",
      "5.0\n",
      "Ok!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Vadimcg\\AppData\\Local\\Temp\\ipykernel_6012\\4025645872.py:19: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  states=np.array(states_batch)\n",
      "C:\\Users\\Vadimcg\\AppData\\Local\\Temp\\ipykernel_6012\\4025645872.py:20: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  actions=np.array(actions_batch)\n"
     ]
    }
   ],
   "source": [
    "states_batch = [\n",
    "    [1, 2, 3],     # game1\n",
    "    [4, 2, 0, 2],  # game2\n",
    "    [3, 1],        # game3\n",
    "]\n",
    "\n",
    "actions_batch = [\n",
    "    [0, 2, 4],     # game1\n",
    "    [3, 2, 0, 1],  # game2\n",
    "    [3, 3],        # game3\n",
    "]\n",
    "rewards_batch = [\n",
    "    3,  # game1\n",
    "    4,  # game2\n",
    "    5,  # game3\n",
    "]\n",
    "\n",
    "test_result_0 = select_elites(states_batch, actions_batch, rewards_batch, percentile=0)\n",
    "test_result_30 = select_elites(states_batch, actions_batch, rewards_batch, percentile=30)\n",
    "test_result_90 = select_elites(states_batch, actions_batch, rewards_batch, percentile=90)\n",
    "test_result_100 = select_elites(states_batch, actions_batch, rewards_batch, percentile=100)\n",
    "\n",
    "assert np.all(test_result_0[0] == [1, 2, 3, 4, 2, 0, 2, 3, 1])  \\\n",
    "    and np.all(test_result_0[1] == [0, 2, 4, 3, 2, 0, 1, 3, 3]), \\\n",
    "    \"For percentile 0 you should return all states and actions in chronological order\"\n",
    "assert np.all(test_result_30[0] == [4, 2, 0, 2, 3, 1]) and \\\n",
    "    np.all(test_result_30[1] == [3, 2, 0, 1, 3, 3]), \\\n",
    "    \"For percentile 30 you should only select states/actions from two first\"\n",
    "assert np.all(test_result_90[0] == [3, 1]) and \\\n",
    "    np.all(test_result_90[1] == [3, 3]), \\\n",
    "    \"For percentile 90 you should only select states/actions from one game\"\n",
    "assert np.all(test_result_100[0] == [3, 1]) and\\\n",
    "    np.all(test_result_100[1] == [3, 3]), \\\n",
    "    \"Please make sure you use >=, not >. Also double-check how you compute percentile.\"\n",
    "\n",
    "print(\"Ok!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_new_policy(elite_states, elite_actions):\n",
    "    \"\"\"\n",
    "    Given a list of elite states/actions from select_elites,\n",
    "    return a new policy where each action probability is proportional to\n",
    "\n",
    "        policy[s_i,a_i] ~ #[occurrences of s_i and a_i in elite states/actions]\n",
    "\n",
    "    Don't forget to normalize the policy to get valid probabilities and handle the 0/0 case.\n",
    "    For states that you never visited, use a uniform distribution (1/n_actions for all states).\n",
    "\n",
    "    :param elite_states: 1D list of states from elite sessions\n",
    "    :param elite_actions: 1D list of actions from elite sessions\n",
    "\n",
    "    \"\"\"\n",
    "    \n",
    "    #print(\"States:{}\".format(len(elite_states)))\n",
    "    #print(\"Actions:{}\".format(len(elite_actions)))\n",
    "\n",
    "    new_policy = np.zeros([n_states, n_actions])\n",
    "\n",
    "\n",
    "    #<YOUR CODE: set probabilities for actions given elite states & actions>\n",
    "    # Don't forget to set 1/n_actions for all actions in unvisited states.\n",
    "    \n",
    "    for i in range(len(elite_states)):\n",
    "        new_policy[elite_states[i],elite_actions[i]]+=1\n",
    "        \n",
    "    \n",
    "    \n",
    "    for i in range(n_states):\n",
    "        if np.sum(new_policy[i])>0:\n",
    "            new_policy[i]/=new_policy[i].sum()\n",
    "        else:\n",
    "            new_policy[i]=np.ones(n_actions)/n_actions\n",
    "            \n",
    "        \n",
    "\n",
    "    return new_policy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ok!\n"
     ]
    }
   ],
   "source": [
    "elite_states = [1, 2, 3, 4, 2, 0, 2, 3, 1]\n",
    "elite_actions = [0, 2, 4, 3, 2, 0, 1, 3, 3]\n",
    "\n",
    "new_policy = get_new_policy(elite_states, elite_actions)\n",
    "\n",
    "assert np.isfinite(new_policy).all(), \\\n",
    "    \"Your new policy contains NaNs or +-inf. Make sure you don't divide by zero.\"\n",
    "assert np.all(new_policy >= 0), \\\n",
    "    \"Your new policy can't have negative action probabilities\"\n",
    "assert np.allclose(new_policy.sum(axis=-1), 1), \\\n",
    "    \"Your new policy should be a valid probability distribution over actions\"\n",
    "\n",
    "reference_answer = np.array([\n",
    "    [1.,  0.,  0.,  0.,  0.],\n",
    "    [0.5,  0.,  0.,  0.5,  0.],\n",
    "    [0.,  0.33333333,  0.66666667,  0.,  0.],\n",
    "    [0.,  0.,  0.,  0.5,  0.5]])\n",
    "assert np.allclose(new_policy[:4, :5], reference_answer)\n",
    "\n",
    "print(\"Ok!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training loop\n",
    "Generate sessions, select N best and fit to those."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import clear_output\n",
    "\n",
    "def show_progress(rewards_batch, log, percentile, reward_range=[-990, +10]):\n",
    "    \"\"\"\n",
    "    A convenience function that displays training progress. \n",
    "    No cool math here, just charts.\n",
    "    \"\"\"\n",
    "\n",
    "    mean_reward = np.mean(rewards_batch)\n",
    "    threshold = np.percentile(rewards_batch, percentile)\n",
    "    log.append([mean_reward, threshold])\n",
    "    \n",
    "    plt.figure(figsize=[8, 4])\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.plot(list(zip(*log))[0], label='Mean rewards')\n",
    "    plt.plot(list(zip(*log))[1], label='Reward thresholds')\n",
    "    plt.legend()\n",
    "    plt.grid()\n",
    "\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.hist(rewards_batch, range=reward_range)\n",
    "    plt.vlines([np.percentile(rewards_batch, percentile)],\n",
    "               [0], [100], label=\"percentile\", color='red')\n",
    "    plt.legend()\n",
    "    plt.grid()\n",
    "    clear_output(True)\n",
    "    print(\"mean reward = %.3f, threshold=%.3f\" % (mean_reward, threshold))\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(500, 6)\n"
     ]
    }
   ],
   "source": [
    "# reset policy just in case\n",
    "policy = initialize_policy(n_states, n_actions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean reward = -118.616, threshold=3.000\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[1;32mIn [19]\u001b[0m, in \u001b[0;36m<cell line: 7>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     18\u001b[0m policy \u001b[38;5;241m=\u001b[39m learning_rate \u001b[38;5;241m*\u001b[39m new_policy \u001b[38;5;241m+\u001b[39m (\u001b[38;5;241m1\u001b[39m \u001b[38;5;241m-\u001b[39m learning_rate) \u001b[38;5;241m*\u001b[39m policy\n\u001b[0;32m     20\u001b[0m \u001b[38;5;66;03m# display results on chart\u001b[39;00m\n\u001b[1;32m---> 21\u001b[0m \u001b[43mshow_progress\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrewards_batch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlog\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpercentile\u001b[49m\u001b[43m)\u001b[49m\n",
      "Input \u001b[1;32mIn [16]\u001b[0m, in \u001b[0;36mshow_progress\u001b[1;34m(rewards_batch, log, percentile, reward_range)\u001b[0m\n\u001b[0;32m     26\u001b[0m clear_output(\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m     27\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmean reward = \u001b[39m\u001b[38;5;132;01m%.3f\u001b[39;00m\u001b[38;5;124m, threshold=\u001b[39m\u001b[38;5;132;01m%.3f\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m (mean_reward, threshold))\n\u001b[1;32m---> 28\u001b[0m \u001b[43mplt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshow\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\miniconda3\\envs\\rl\\lib\\site-packages\\matplotlib\\pyplot.py:368\u001b[0m, in \u001b[0;36mshow\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    324\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    325\u001b[0m \u001b[38;5;124;03mDisplay all open figures.\u001b[39;00m\n\u001b[0;32m    326\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    365\u001b[0m \u001b[38;5;124;03mexplicitly there.\u001b[39;00m\n\u001b[0;32m    366\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    367\u001b[0m _warn_if_gui_out_of_main_thread()\n\u001b[1;32m--> 368\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m _backend_mod\u001b[38;5;241m.\u001b[39mshow(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\miniconda3\\envs\\rl\\lib\\site-packages\\matplotlib_inline\\backend_inline.py:41\u001b[0m, in \u001b[0;36mshow\u001b[1;34m(close, block)\u001b[0m\n\u001b[0;32m     39\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     40\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m figure_manager \u001b[38;5;129;01min\u001b[39;00m Gcf\u001b[38;5;241m.\u001b[39mget_all_fig_managers():\n\u001b[1;32m---> 41\u001b[0m         \u001b[43mdisplay\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m     42\u001b[0m \u001b[43m            \u001b[49m\u001b[43mfigure_manager\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcanvas\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfigure\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     43\u001b[0m \u001b[43m            \u001b[49m\u001b[43mmetadata\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m_fetch_figure_metadata\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfigure_manager\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcanvas\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfigure\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     44\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     45\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m     46\u001b[0m     show\u001b[38;5;241m.\u001b[39m_to_draw \u001b[38;5;241m=\u001b[39m []\n",
      "File \u001b[1;32m~\\miniconda3\\envs\\rl\\lib\\site-packages\\IPython\\core\\display_functions.py:298\u001b[0m, in \u001b[0;36mdisplay\u001b[1;34m(include, exclude, metadata, transient, display_id, raw, clear, *objs, **kwargs)\u001b[0m\n\u001b[0;32m    296\u001b[0m     publish_display_data(data\u001b[38;5;241m=\u001b[39mobj, metadata\u001b[38;5;241m=\u001b[39mmetadata, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    297\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 298\u001b[0m     format_dict, md_dict \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mformat\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mobj\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minclude\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minclude\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexclude\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mexclude\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    299\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m format_dict:\n\u001b[0;32m    300\u001b[0m         \u001b[38;5;66;03m# nothing to display (e.g. _ipython_display_ took over)\u001b[39;00m\n\u001b[0;32m    301\u001b[0m         \u001b[38;5;28;01mcontinue\u001b[39;00m\n",
      "File \u001b[1;32m~\\miniconda3\\envs\\rl\\lib\\site-packages\\IPython\\core\\formatters.py:178\u001b[0m, in \u001b[0;36mDisplayFormatter.format\u001b[1;34m(self, obj, include, exclude)\u001b[0m\n\u001b[0;32m    176\u001b[0m md \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    177\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 178\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[43mformatter\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobj\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    179\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m:\n\u001b[0;32m    180\u001b[0m     \u001b[38;5;66;03m# FIXME: log the exception\u001b[39;00m\n\u001b[0;32m    181\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m\n",
      "File \u001b[1;32m~\\miniconda3\\envs\\rl\\lib\\site-packages\\decorator.py:232\u001b[0m, in \u001b[0;36mdecorate.<locals>.fun\u001b[1;34m(*args, **kw)\u001b[0m\n\u001b[0;32m    230\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m kwsyntax:\n\u001b[0;32m    231\u001b[0m     args, kw \u001b[38;5;241m=\u001b[39m fix(args, kw, sig)\n\u001b[1;32m--> 232\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m caller(func, \u001b[38;5;241m*\u001b[39m(extras \u001b[38;5;241m+\u001b[39m args), \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkw)\n",
      "File \u001b[1;32m~\\miniconda3\\envs\\rl\\lib\\site-packages\\IPython\\core\\formatters.py:222\u001b[0m, in \u001b[0;36mcatch_format_error\u001b[1;34m(method, self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    220\u001b[0m \u001b[38;5;124;03m\"\"\"show traceback on failed format call\"\"\"\u001b[39;00m\n\u001b[0;32m    221\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 222\u001b[0m     r \u001b[38;5;241m=\u001b[39m method(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    223\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mNotImplementedError\u001b[39;00m:\n\u001b[0;32m    224\u001b[0m     \u001b[38;5;66;03m# don't warn on NotImplementedErrors\u001b[39;00m\n\u001b[0;32m    225\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_return(\u001b[38;5;28;01mNone\u001b[39;00m, args[\u001b[38;5;241m0\u001b[39m])\n",
      "File \u001b[1;32m~\\miniconda3\\envs\\rl\\lib\\site-packages\\IPython\\core\\formatters.py:339\u001b[0m, in \u001b[0;36mBaseFormatter.__call__\u001b[1;34m(self, obj)\u001b[0m\n\u001b[0;32m    337\u001b[0m     \u001b[38;5;28;01mpass\u001b[39;00m\n\u001b[0;32m    338\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 339\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mprinter\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobj\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    340\u001b[0m \u001b[38;5;66;03m# Finally look for special method names\u001b[39;00m\n\u001b[0;32m    341\u001b[0m method \u001b[38;5;241m=\u001b[39m get_real_method(obj, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprint_method)\n",
      "File \u001b[1;32m~\\miniconda3\\envs\\rl\\lib\\site-packages\\IPython\\core\\pylabtools.py:151\u001b[0m, in \u001b[0;36mprint_figure\u001b[1;34m(fig, fmt, bbox_inches, base64, **kwargs)\u001b[0m\n\u001b[0;32m    148\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbackend_bases\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m FigureCanvasBase\n\u001b[0;32m    149\u001b[0m     FigureCanvasBase(fig)\n\u001b[1;32m--> 151\u001b[0m fig\u001b[38;5;241m.\u001b[39mcanvas\u001b[38;5;241m.\u001b[39mprint_figure(bytes_io, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkw)\n\u001b[0;32m    152\u001b[0m data \u001b[38;5;241m=\u001b[39m bytes_io\u001b[38;5;241m.\u001b[39mgetvalue()\n\u001b[0;32m    153\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m fmt \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124msvg\u001b[39m\u001b[38;5;124m'\u001b[39m:\n",
      "File \u001b[1;32m~\\miniconda3\\envs\\rl\\lib\\site-packages\\matplotlib\\backend_bases.py:2295\u001b[0m, in \u001b[0;36mFigureCanvasBase.print_figure\u001b[1;34m(self, filename, dpi, facecolor, edgecolor, orientation, format, bbox_inches, pad_inches, bbox_extra_artists, backend, **kwargs)\u001b[0m\n\u001b[0;32m   2289\u001b[0m     renderer \u001b[38;5;241m=\u001b[39m _get_renderer(\n\u001b[0;32m   2290\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfigure,\n\u001b[0;32m   2291\u001b[0m         functools\u001b[38;5;241m.\u001b[39mpartial(\n\u001b[0;32m   2292\u001b[0m             print_method, orientation\u001b[38;5;241m=\u001b[39morientation)\n\u001b[0;32m   2293\u001b[0m     )\n\u001b[0;32m   2294\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(renderer, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_draw_disabled\u001b[39m\u001b[38;5;124m\"\u001b[39m, nullcontext)():\n\u001b[1;32m-> 2295\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfigure\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdraw\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrenderer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   2297\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m bbox_inches:\n\u001b[0;32m   2298\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m bbox_inches \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtight\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n",
      "File \u001b[1;32m~\\miniconda3\\envs\\rl\\lib\\site-packages\\matplotlib\\artist.py:73\u001b[0m, in \u001b[0;36m_finalize_rasterization.<locals>.draw_wrapper\u001b[1;34m(artist, renderer, *args, **kwargs)\u001b[0m\n\u001b[0;32m     71\u001b[0m \u001b[38;5;129m@wraps\u001b[39m(draw)\n\u001b[0;32m     72\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdraw_wrapper\u001b[39m(artist, renderer, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m---> 73\u001b[0m     result \u001b[38;5;241m=\u001b[39m draw(artist, renderer, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m     74\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m renderer\u001b[38;5;241m.\u001b[39m_rasterizing:\n\u001b[0;32m     75\u001b[0m         renderer\u001b[38;5;241m.\u001b[39mstop_rasterizing()\n",
      "File \u001b[1;32m~\\miniconda3\\envs\\rl\\lib\\site-packages\\matplotlib\\artist.py:50\u001b[0m, in \u001b[0;36mallow_rasterization.<locals>.draw_wrapper\u001b[1;34m(artist, renderer)\u001b[0m\n\u001b[0;32m     47\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m artist\u001b[38;5;241m.\u001b[39mget_agg_filter() \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m     48\u001b[0m         renderer\u001b[38;5;241m.\u001b[39mstart_filter()\n\u001b[1;32m---> 50\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mdraw\u001b[49m\u001b[43m(\u001b[49m\u001b[43martist\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrenderer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     51\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m     52\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m artist\u001b[38;5;241m.\u001b[39mget_agg_filter() \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[1;32m~\\miniconda3\\envs\\rl\\lib\\site-packages\\matplotlib\\figure.py:2810\u001b[0m, in \u001b[0;36mFigure.draw\u001b[1;34m(self, renderer)\u001b[0m\n\u001b[0;32m   2807\u001b[0m         \u001b[38;5;66;03m# ValueError can occur when resizing a window.\u001b[39;00m\n\u001b[0;32m   2809\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpatch\u001b[38;5;241m.\u001b[39mdraw(renderer)\n\u001b[1;32m-> 2810\u001b[0m \u001b[43mmimage\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_draw_list_compositing_images\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   2811\u001b[0m \u001b[43m    \u001b[49m\u001b[43mrenderer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43martists\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msuppressComposite\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   2813\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m sfig \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msubfigs:\n\u001b[0;32m   2814\u001b[0m     sfig\u001b[38;5;241m.\u001b[39mdraw(renderer)\n",
      "File \u001b[1;32m~\\miniconda3\\envs\\rl\\lib\\site-packages\\matplotlib\\image.py:132\u001b[0m, in \u001b[0;36m_draw_list_compositing_images\u001b[1;34m(renderer, parent, artists, suppress_composite)\u001b[0m\n\u001b[0;32m    130\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m not_composite \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m has_images:\n\u001b[0;32m    131\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m a \u001b[38;5;129;01min\u001b[39;00m artists:\n\u001b[1;32m--> 132\u001b[0m         \u001b[43ma\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdraw\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrenderer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    133\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    134\u001b[0m     \u001b[38;5;66;03m# Composite any adjacent images together\u001b[39;00m\n\u001b[0;32m    135\u001b[0m     image_group \u001b[38;5;241m=\u001b[39m []\n",
      "File \u001b[1;32m~\\miniconda3\\envs\\rl\\lib\\site-packages\\matplotlib\\artist.py:50\u001b[0m, in \u001b[0;36mallow_rasterization.<locals>.draw_wrapper\u001b[1;34m(artist, renderer)\u001b[0m\n\u001b[0;32m     47\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m artist\u001b[38;5;241m.\u001b[39mget_agg_filter() \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m     48\u001b[0m         renderer\u001b[38;5;241m.\u001b[39mstart_filter()\n\u001b[1;32m---> 50\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mdraw\u001b[49m\u001b[43m(\u001b[49m\u001b[43martist\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrenderer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     51\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m     52\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m artist\u001b[38;5;241m.\u001b[39mget_agg_filter() \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[1;32m~\\miniconda3\\envs\\rl\\lib\\site-packages\\matplotlib\\axes\\_base.py:3082\u001b[0m, in \u001b[0;36m_AxesBase.draw\u001b[1;34m(self, renderer)\u001b[0m\n\u001b[0;32m   3079\u001b[0m         a\u001b[38;5;241m.\u001b[39mdraw(renderer)\n\u001b[0;32m   3080\u001b[0m     renderer\u001b[38;5;241m.\u001b[39mstop_rasterizing()\n\u001b[1;32m-> 3082\u001b[0m \u001b[43mmimage\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_draw_list_compositing_images\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   3083\u001b[0m \u001b[43m    \u001b[49m\u001b[43mrenderer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43martists\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfigure\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msuppressComposite\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   3085\u001b[0m renderer\u001b[38;5;241m.\u001b[39mclose_group(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124maxes\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m   3086\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstale \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n",
      "File \u001b[1;32m~\\miniconda3\\envs\\rl\\lib\\site-packages\\matplotlib\\image.py:132\u001b[0m, in \u001b[0;36m_draw_list_compositing_images\u001b[1;34m(renderer, parent, artists, suppress_composite)\u001b[0m\n\u001b[0;32m    130\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m not_composite \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m has_images:\n\u001b[0;32m    131\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m a \u001b[38;5;129;01min\u001b[39;00m artists:\n\u001b[1;32m--> 132\u001b[0m         \u001b[43ma\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdraw\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrenderer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    133\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    134\u001b[0m     \u001b[38;5;66;03m# Composite any adjacent images together\u001b[39;00m\n\u001b[0;32m    135\u001b[0m     image_group \u001b[38;5;241m=\u001b[39m []\n",
      "File \u001b[1;32m~\\miniconda3\\envs\\rl\\lib\\site-packages\\matplotlib\\artist.py:50\u001b[0m, in \u001b[0;36mallow_rasterization.<locals>.draw_wrapper\u001b[1;34m(artist, renderer)\u001b[0m\n\u001b[0;32m     47\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m artist\u001b[38;5;241m.\u001b[39mget_agg_filter() \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m     48\u001b[0m         renderer\u001b[38;5;241m.\u001b[39mstart_filter()\n\u001b[1;32m---> 50\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mdraw\u001b[49m\u001b[43m(\u001b[49m\u001b[43martist\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrenderer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     51\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m     52\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m artist\u001b[38;5;241m.\u001b[39mget_agg_filter() \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[1;32m~\\miniconda3\\envs\\rl\\lib\\site-packages\\matplotlib\\legend.py:628\u001b[0m, in \u001b[0;36mLegend.draw\u001b[1;34m(self, renderer)\u001b[0m\n\u001b[0;32m    625\u001b[0m     Shadow(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlegendPatch, \u001b[38;5;241m2\u001b[39m, \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m2\u001b[39m)\u001b[38;5;241m.\u001b[39mdraw(renderer)\n\u001b[0;32m    627\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlegendPatch\u001b[38;5;241m.\u001b[39mdraw(renderer)\n\u001b[1;32m--> 628\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_legend_box\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdraw\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrenderer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    630\u001b[0m renderer\u001b[38;5;241m.\u001b[39mclose_group(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlegend\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m    631\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstale \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n",
      "File \u001b[1;32m~\\miniconda3\\envs\\rl\\lib\\site-packages\\matplotlib\\offsetbox.py:362\u001b[0m, in \u001b[0;36mOffsetBox.draw\u001b[1;34m(self, renderer)\u001b[0m\n\u001b[0;32m    355\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    356\u001b[0m \u001b[38;5;124;03mUpdate the location of children if necessary and draw them\u001b[39;00m\n\u001b[0;32m    357\u001b[0m \u001b[38;5;124;03mto the given *renderer*.\u001b[39;00m\n\u001b[0;32m    358\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    359\u001b[0m width, height, xdescent, ydescent, offsets \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_extent_offsets(\n\u001b[0;32m    360\u001b[0m                                                 renderer)\n\u001b[1;32m--> 362\u001b[0m px, py \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_offset\u001b[49m\u001b[43m(\u001b[49m\u001b[43mwidth\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mheight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mxdescent\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mydescent\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrenderer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    364\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m c, (ox, oy) \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_visible_children(), offsets):\n\u001b[0;32m    365\u001b[0m     c\u001b[38;5;241m.\u001b[39mset_offset((px \u001b[38;5;241m+\u001b[39m ox, py \u001b[38;5;241m+\u001b[39m oy))\n",
      "File \u001b[1;32m~\\miniconda3\\envs\\rl\\lib\\site-packages\\matplotlib\\offsetbox.py:290\u001b[0m, in \u001b[0;36mOffsetBox.get_offset\u001b[1;34m(self, width, height, xdescent, ydescent, renderer)\u001b[0m\n\u001b[0;32m    275\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget_offset\u001b[39m(\u001b[38;5;28mself\u001b[39m, width, height, xdescent, ydescent, renderer):\n\u001b[0;32m    276\u001b[0m     \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    277\u001b[0m \u001b[38;5;124;03m    Return the offset as a tuple (x, y).\u001b[39;00m\n\u001b[0;32m    278\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    288\u001b[0m \n\u001b[0;32m    289\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 290\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m (\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_offset\u001b[49m\u001b[43m(\u001b[49m\u001b[43mwidth\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mheight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mxdescent\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mydescent\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrenderer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    291\u001b[0m             \u001b[38;5;28;01mif\u001b[39;00m callable(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_offset)\n\u001b[0;32m    292\u001b[0m             \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_offset)\n",
      "File \u001b[1;32m~\\miniconda3\\envs\\rl\\lib\\site-packages\\matplotlib\\legend.py:589\u001b[0m, in \u001b[0;36mLegend._findoffset\u001b[1;34m(self, width, height, xdescent, ydescent, renderer)\u001b[0m\n\u001b[0;32m    586\u001b[0m \u001b[38;5;124;03m\"\"\"Helper function to locate the legend.\"\"\"\u001b[39;00m\n\u001b[0;32m    588\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_loc \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:  \u001b[38;5;66;03m# \"best\".\u001b[39;00m\n\u001b[1;32m--> 589\u001b[0m     x, y \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_find_best_position\u001b[49m\u001b[43m(\u001b[49m\u001b[43mwidth\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mheight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrenderer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    590\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_loc \u001b[38;5;129;01min\u001b[39;00m Legend\u001b[38;5;241m.\u001b[39mcodes\u001b[38;5;241m.\u001b[39mvalues():  \u001b[38;5;66;03m# Fixed location.\u001b[39;00m\n\u001b[0;32m    591\u001b[0m     bbox \u001b[38;5;241m=\u001b[39m Bbox\u001b[38;5;241m.\u001b[39mfrom_bounds(\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m0\u001b[39m, width, height)\n",
      "File \u001b[1;32m~\\miniconda3\\envs\\rl\\lib\\site-packages\\matplotlib\\legend.py:1033\u001b[0m, in \u001b[0;36mLegend._find_best_position\u001b[1;34m(self, width, height, renderer, consider)\u001b[0m\n\u001b[0;32m   1027\u001b[0m badness \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[0;32m   1028\u001b[0m \u001b[38;5;66;03m# XXX TODO: If markers are present, it would be good to take them\u001b[39;00m\n\u001b[0;32m   1029\u001b[0m \u001b[38;5;66;03m# into account when checking vertex overlaps in the next line.\u001b[39;00m\n\u001b[0;32m   1030\u001b[0m badness \u001b[38;5;241m=\u001b[39m (\u001b[38;5;28msum\u001b[39m(legendBox\u001b[38;5;241m.\u001b[39mcount_contains(line\u001b[38;5;241m.\u001b[39mvertices)\n\u001b[0;32m   1031\u001b[0m                \u001b[38;5;28;01mfor\u001b[39;00m line \u001b[38;5;129;01min\u001b[39;00m lines)\n\u001b[0;32m   1032\u001b[0m            \u001b[38;5;241m+\u001b[39m legendBox\u001b[38;5;241m.\u001b[39mcount_contains(offsets)\n\u001b[1;32m-> 1033\u001b[0m            \u001b[38;5;241m+\u001b[39m \u001b[43mlegendBox\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcount_overlaps\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbboxes\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1034\u001b[0m            \u001b[38;5;241m+\u001b[39m \u001b[38;5;28msum\u001b[39m(line\u001b[38;5;241m.\u001b[39mintersects_bbox(legendBox, filled\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[0;32m   1035\u001b[0m                  \u001b[38;5;28;01mfor\u001b[39;00m line \u001b[38;5;129;01min\u001b[39;00m lines))\n\u001b[0;32m   1036\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m badness \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m   1037\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m l, b\n",
      "File \u001b[1;32m~\\miniconda3\\envs\\rl\\lib\\site-packages\\matplotlib\\transforms.py:618\u001b[0m, in \u001b[0;36mBboxBase.count_overlaps\u001b[1;34m(self, bboxes)\u001b[0m\n\u001b[0;32m    609\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcount_overlaps\u001b[39m(\u001b[38;5;28mself\u001b[39m, bboxes):\n\u001b[0;32m    610\u001b[0m     \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    611\u001b[0m \u001b[38;5;124;03m    Count the number of bounding boxes that overlap this one.\u001b[39;00m\n\u001b[0;32m    612\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    615\u001b[0m \u001b[38;5;124;03m    bboxes : sequence of `.BboxBase`\u001b[39;00m\n\u001b[0;32m    616\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m    617\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m count_bboxes_overlapping_bbox(\n\u001b[1;32m--> 618\u001b[0m         \u001b[38;5;28mself\u001b[39m, \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43matleast_3d\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43marray\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mbboxes\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m)\n",
      "File \u001b[1;32m<__array_function__ internals>:5\u001b[0m, in \u001b[0;36matleast_3d\u001b[1;34m(*args, **kwargs)\u001b[0m\n",
      "File \u001b[1;32m~\\miniconda3\\envs\\rl\\lib\\site-packages\\numpy\\core\\shape_base.py:191\u001b[0m, in \u001b[0;36matleast_3d\u001b[1;34m(*arys)\u001b[0m\n\u001b[0;32m    189\u001b[0m res \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m    190\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m ary \u001b[38;5;129;01min\u001b[39;00m arys:\n\u001b[1;32m--> 191\u001b[0m     ary \u001b[38;5;241m=\u001b[39m \u001b[43masanyarray\u001b[49m\u001b[43m(\u001b[49m\u001b[43mary\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    192\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m ary\u001b[38;5;241m.\u001b[39mndim \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m    193\u001b[0m         result \u001b[38;5;241m=\u001b[39m ary\u001b[38;5;241m.\u001b[39mreshape(\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m1\u001b[39m)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "n_sessions = 250     # sample this many sessions\n",
    "percentile = 40      # take this percent of session with highest rewards\n",
    "learning_rate = 0.5  # how quickly the policy is updated, on a scale from 0 to 1\n",
    "\n",
    "log = []\n",
    "\n",
    "for i in range(100):\n",
    "    # Генерируем игровые ссесии\n",
    "    %time sessions =  [generate_session(env, policy, t_max=1000) for _ in range(n_sessions)]\n",
    "\n",
    "    states_batch, actions_batch, rewards_batch = zip(*sessions)\n",
    "\n",
    "    # Выбираем состояния и действия при которых награда больше персентиля\n",
    "    elite_states, elite_actions = select_elites(states_batch, actions_batch, rewards_batch, percentile=percentile)\n",
    "    \n",
    "    new_policy =get_new_policy(elite_states,elite_actions)\n",
    "    # Обновляем политику\n",
    "    policy = learning_rate * new_policy + (1 - learning_rate) * policy\n",
    "\n",
    "    # display results on chart\n",
    "    show_progress(rewards_batch, log, percentile)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reflecting on results\n",
    "\n",
    "You may have noticed that the taxi problem quickly converges from less than -1000 to a near-optimal score and then descends back into -50/-100. This is in part because the environment has some innate randomness. Namely, the starting points of passenger/driver change from episode to episode.\n",
    "\n",
    "In case CEM failed to learn how to win from one distinct starting point, it will simply discard it because no sessions from that starting point will make it into the \"elites\".\n",
    "\n",
    "To mitigate that problem, you can either reduce the threshold for elite sessions (duct tape way) or change the way you evaluate strategy (theoretically correct way). For each starting state, you can sample an action randomly, and then evaluate this action by running _several_ games starting from it and averaging the total reward. Choosing elite sessions with this kind of sampling (where each session's reward is counted as the average of the rewards of all sessions with the same starting state and action) should improve the performance of your policy."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### You're not done yet!\n",
    "\n",
    "Go to [`./deep_crossentropy_method.ipynb`](./deep_crossentropy_method.ipynb) for a more serious task"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
